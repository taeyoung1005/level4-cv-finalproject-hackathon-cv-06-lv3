import { createSlice, createAsyncThunk } from "@reduxjs/toolkit";

const API_BASE_URL = "http://10.28.224.157:30258/data-processing";

//
// -------------------- Flows API Thunks --------------------
//

// ÌäπÏ†ï ÌîÑÎ°úÏ†ùÌä∏Ïùò Flows Í∞ÄÏ†∏Ïò§Í∏∞
export const fetchFlowsByProject = createAsyncThunk(
  "flows/fetchFlowsByProject",
  async (projectId, { rejectWithValue }) => {
    try {
      const response = await fetch(
        `${API_BASE_URL}/flows/?project_id=${projectId}`
      );
      if (!response.ok) throw new Error("Failed to fetch flows");

      const data = await response.json();
      console.log("üîπ API ÏùëÎãµ:", data);

      if (!Array.isArray(data.flows)) {
        throw new Error("Invalid response format: flows is not an array");
      }

      // ‚úÖ "flows" ÌÇ§ ÏïÑÎûòÏùò Î∞∞Ïó¥ÏùÑ Î≥ÄÌôò (id ‚Üí flowId)
      const formattedFlows = Object.fromEntries(
        data.flows.map((flow) => [
          flow.id,
          { ...flow, flowId: flow.id, projectId },
        ])
      );

      console.log("‚úÖ Î≥ÄÌôòÎêú Flow Îç∞Ïù¥ÌÑ∞:", formattedFlows);
      return { projectId, flows: formattedFlows };
    } catch (error) {
      return rejectWithValue(error.message);
    }
  }
);

// Flow Ï∂îÍ∞Ä
export const addFlowAsync = createAsyncThunk(
  "flows/addFlow",
  async ({ projectId, flowName }, { rejectWithValue }) => {
    try {
      const response = await fetch(`${API_BASE_URL}/flows/`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ project_id: projectId, flow_name: flowName }),
      });

      if (!response.ok) throw new Error("Failed to add flow");

      const newFlow = await response.json();

      return {
        flowId: newFlow.flow_id,
        flow: {
          flowId: newFlow.flow_id,
          projectId,
          flow_name: flowName, // ‚úÖ flow_name Ï†ÄÏû•
        },
      };
    } catch (error) {
      return rejectWithValue(error.message);
    }
  }
);

// Flow ÏàòÏ†ï
export const editFlowAsync = createAsyncThunk(
  "flows/editFlow",
  async ({ flowId, flowName }, { rejectWithValue }) => {
    try {
      const response = await fetch(`${API_BASE_URL}/flows/`, {
        method: "PUT",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ flow_id: flowId, flow_name: flowName }),
      });

      if (!response.ok) throw new Error("Failed to edit flow");

      return { flowId, flowName };
    } catch (error) {
      return rejectWithValue(error.message);
    }
  }
);

// Flow ÏÇ≠Ï†ú
export const deleteFlowAsync = createAsyncThunk(
  "flows/deleteFlow",
  async ({ flowId }, { rejectWithValue }) => {
    try {
      const response = await fetch(`${API_BASE_URL}/flows/`, {
        method: "DELETE",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ flow_id: flowId }),
      });

      if (!response.ok) throw new Error("Failed to delete flow");

      return flowId;
    } catch (error) {
      return rejectWithValue(error.message);
    }
  }
);

//
// -------------------- Dataset Í¥ÄÎ†® Thunks Ï∂îÍ∞Ä --------------------
//

// ‚úÖ ÌäπÏ†ï FlowÏóê Ï∂îÍ∞ÄÎêú CSV Î™©Î°ù Ï°∞Ìöå
export const fetchFlowDatasets = createAsyncThunk(
  "flows/fetchFlowDatasets",
  async (flowId, { rejectWithValue }) => {
    try {
      const response = await fetch(
        `${API_BASE_URL}/flows/csv-add/?flow_id=${flowId}`
      );
      if (!response.ok) throw new Error("Failed to fetch flow datasets");

      const data = await response.json();
      console.log("üîπ Flow Datasets API Response:", data);

      // üîç ÏùëÎãµ Í≤ÄÏ¶ù
      if (!data.csvs || !Array.isArray(data.csvs)) {
        console.error(
          "‚ùå API response does not contain a valid csvs array:",
          data
        );
        return rejectWithValue("Invalid API response");
      }

      // ‚úÖ "csvs" Î∞∞Ïó¥ÏùÑ Î≥ÄÌôòÌïòÏó¨ flowÏóê Ï†ÄÏû•
      const formattedDatasets = data.csvs.map(({ id, csv_name }) => {
        if (typeof csv_name !== "string") {
          console.error("‚ùå Invalid csv_name:", csv_name);
          return { csvId: id, fileName: "Unknown" }; // Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï
        }

        return {
          csvId: id,
          fileName: csv_name,
        };
      });

      console.log("‚úÖ Transformed Flow Datasets:", formattedDatasets);

      return { flowId, datasets: formattedDatasets };
    } catch (error) {
      console.error("‚ùå fetchFlowDatasets Error:", error);
      return rejectWithValue(error.message);
    }
  }
);

// ‚úÖ FlowÏóê CSV Ï∂îÍ∞Ä
export const addCsvToFlow = createAsyncThunk(
  "flows/addCsvToFlow",
  async ({ flowId, csvIds }, { rejectWithValue }) => {
    try {
      const response = await fetch(`${API_BASE_URL}/flows/csv-add/`, {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ flow_id: parseInt(flowId), csv_ids: csvIds }),
      });

      if (!response.ok) throw new Error("Failed to add CSV to flow");

      return { flowId, csvIds };
    } catch (error) {
      return rejectWithValue(error.message);
    }
  }
);

// ‚úÖ ÌäπÏ†ï FlowÏùò properties Ï°∞Ìöå
export const fetchFlowProperties = createAsyncThunk(
  "flows/fetchFlowProperties",
  async (flowId, { rejectWithValue }) => {
    try {
      const response = await fetch(
        `${API_BASE_URL}/concat-columns/?flow_id=${flowId}`
      );
      if (!response.ok) throw new Error("Failed to fetch properties");

      const data = await response.json();
      console.log("‚úÖ Properties API Response:", data);

      return { flowId, properties: data };
    } catch (error) {
      console.error("‚ùå Error fetching properties:", error);
      return rejectWithValue(error.message);
    }
  }
);

// ‚úÖ ÌäπÏ†ï FlowÏùò ÌûàÏä§ÌÜ†Í∑∏Îû® Îç∞Ïù¥ÌÑ∞ Í∞ÄÏ†∏Ïò§Í∏∞
export const fetchFlowHistograms = createAsyncThunk(
  "flows/fetchFlowHistograms",
  async (flowId, { rejectWithValue }) => {
    try {
      const response = await fetch(
        `${API_BASE_URL}/histograms/all?flow_id=${flowId}`
      );
      if (!response.ok) throw new Error("Failed to fetch histograms");

      const data = await response.json();
      console.log("‚úÖ Histograms API Response:", data);

      return { flowId, histograms: data.histograms };
    } catch (error) {
      console.error("‚ùå Error fetching histograms:", error);
      return rejectWithValue(error.message);
    }
  }
);

// ‚úÖ ÏÉàÎ°úÏö¥ Ïπ¥ÌÖåÍ≥†Î¶¨ Ï†ïÎ≥¥ PUT ÏöîÏ≤≠ (Next Step Î≤ÑÌäº ÌÅ¥Î¶≠ Ïãú Ïã§Ìñâ)
export const savePropertyCategories = createAsyncThunk(
  "flows/savePropertyCategories",
  async ({ flowId, update }, { rejectWithValue }) => {
    try {
      const response = await fetch(`${API_BASE_URL}/concat-columns/`, {
        method: "PUT",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify(update),
      });

      if (!response.ok) throw new Error("Failed to update property categories");

      return { flowId, update };
    } catch (error) {
      return rejectWithValue(error.message);
    }
  }
);

// ‚úÖ Ïö∞ÏÑ†ÏàúÏúÑ Ï†ÄÏû• API Ìò∏Ï∂ú
export const savePriorities = createAsyncThunk(
  "flows/savePriorities",
  async ({ flowId, priorities }, { rejectWithValue }) => {
    try {
      const response = await fetch(`${API_BASE_URL}/priorities/`, {
        method: "PUT",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({ flow_id: flowId, priorities }),
      });

      if (!response.ok) throw new Error("Failed to save priorities");

      return { flowId, priorities };
    } catch (error) {
      return rejectWithValue(error.message);
    }
  }
);

//
// -------------------- Redux Slice --------------------
//

const initialState = {
  flows: {}, // FlowÎ≥Ñ ÏÉÅÌÉú Í¥ÄÎ¶¨ (flowId Í∏∞Î∞ò Ï†ÄÏû•)
  priorities: {},
  optimizationData: {},
  histograms: {},
  properties: {}, // ‚úÖ concat_csv_idÎ•º ÌÇ§Î°ú ÌïòÎäî properties Ï†ÄÏû• Í≥µÍ∞Ñ Ï∂îÍ∞Ä
  newCategories: {},
  status: "idle",
  error: null,
};

const flowSlice = createSlice({
  name: "flows",
  initialState,
  reducers: {
    initializeFlow: (state, action) => {
      const { flowId, concatCsvId = 3 } = action.payload; // ‚úÖ Í∏∞Î≥∏Í∞í ÏÑ§Ï†ï
      if (!state.flows[flowId]) {
        state.flows[flowId] = {
          datasets: [],
          concat_csv_id: concatCsvId, // ‚úÖ Í∏∞Î≥∏Í∞í Ï†ÅÏö©
        };
      }
    },
    setCurrentStep: (state, action) => {
      const { flowId, step } = action.payload;
      if (state.flows[flowId]) {
        state.flows[flowId].currentStep = step;
      }
    },
    setConcatCsvId: (state, action) => {
      const { flowId, concatCsvId } = action.payload;
      if (state.flows[flowId]) {
        state.flows[flowId].concat_csv_id = concatCsvId;
      }
    },
    initializeCategories: (state, action) => {
      const { flowId, properties } = action.payload;

      if (!state.properties[flowId]) {
        state.properties[flowId] = properties; // ‚úÖ Í∏∞Ï°¥ properties Ï†ÄÏû•
      }

      if (!state.newCategories[flowId]) {
        state.newCategories[flowId] = {}; // ‚úÖ ÏÉàÎ°úÏö¥ category Ï†ÄÏû• Í≥µÍ∞Ñ Ï¥àÍ∏∞Ìôî
      }
    },

    updateCategory: (state, action) => {
      const { flowId, property, category } = action.payload;

      if (!state.newCategories[flowId]) {
        state.newCategories[flowId] = {};
      }

      // ‚úÖ propertyÏóê ÎåÄÌïú ÏÉàÎ°úÏö¥ category Ï†ïÎ≥¥ Ï∂îÍ∞Ä
      state.newCategories[flowId][property] = category;
    },
    updateOptimizationData: (state, action) => {
      const { flowId, property, newData, type } = action.payload;
      if (!state.optimizationData[flowId]) {
        state.optimizationData[flowId] = {};
      }
      state.optimizationData[flowId][property] = {
        ...state.optimizationData[flowId][property],
        ...newData,
        type,
      };
    },
    updatePriorities: (state, action) => {
      const { flowId, priorities } = action.payload;
      state.priorities[flowId] = priorities;
    },
    initializePriorities: (state, action) => {
      const { flowId } = action.payload;

      if (!state.priorities[flowId] && state.optimizationData[flowId]) {
        state.priorities[flowId] = Object.keys(state.optimizationData[flowId]);
      }
    },
  },
  extraReducers: (builder) => {
    builder
      .addCase(fetchFlowsByProject.fulfilled, (state, action) => {
        const { flows } = action.payload;
        state.flows = { ...state.flows, ...flows };
      })
      .addCase(fetchFlowsByProject.rejected, (state, action) => {
        console.error("‚ùå Flow Îç∞Ïù¥ÌÑ∞ ÏöîÏ≤≠ Ïã§Ìå®:", action.payload);
        state.error = action.payload;
      })
      .addCase(addFlowAsync.fulfilled, (state, action) => {
        const { flowId, flow } = action.payload;
        state.flows[flowId] = flow;
      })
      .addCase(deleteFlowAsync.fulfilled, (state, action) => {
        delete state.flows[action.payload];
      })
      .addCase(editFlowAsync.fulfilled, (state, action) => {
        const { flowId, flowName } = action.payload;
        if (state.flows[flowId]) {
          state.flows[flowId].flow_name = flowName;
        }
      })
      // ‚úÖ FlowÏóê Ï∂îÍ∞ÄÎêú CSV Î™©Î°ù Ï°∞Ìöå ÏÑ±Í≥µ
      .addCase(fetchFlowDatasets.fulfilled, (state, action) => {
        const { flowId, datasets } = action.payload;
        if (!state.flows[flowId]) {
          state.flows[flowId] = { datasets: [] };
        }
        console.log(datasets);
        state.flows[flowId].datasets = datasets.map((p) => p.csvId);
        console.log(state.flows[flowId].datasets);
      })
      .addCase(fetchFlowDatasets.rejected, (state, action) => {
        console.error("‚ùå Failed to fetch flow datasets:", action.payload);
        state.error = action.payload;
      })

      // ‚úÖ FlowÏóê CSV Ï∂îÍ∞Ä ÏÑ±Í≥µ
      .addCase(addCsvToFlow.fulfilled, (state, action) => {
        const { flowId, csvIds } = action.payload;

        if (!state.flows[flowId]) {
          state.flows[flowId] = { datasets: [] };
        }

        // Í∏∞Ï°¥ csvId Î¶¨Ïä§Ìä∏ Í∞ÄÏ†∏Ïò§Í∏∞ (Í∏∞Î≥∏Ï†ÅÏúºÎ°ú Îπà Î∞∞Ïó¥)
        const existingIds = state.flows[flowId].datasets || [];

        // Ï§ëÎ≥µÎêòÏßÄ ÏïäÏùÄ ÏÉàÎ°úÏö¥ csvIdÎßå Ï∂îÍ∞Ä
        const newDatasets = csvIds.filter((id) => !existingIds.includes(id));

        console.log("newDatasets (Ï∂îÍ∞ÄÌï† CSV ID):", newDatasets);

        // ÏµúÏ¢ÖÏ†ÅÏúºÎ°ú csvId Î∞∞Ïó¥ÏùÑ Ïú†ÏßÄ
        state.flows[flowId].datasets = [...existingIds, ...newDatasets];
      })
      .addCase(addCsvToFlow.rejected, (state, action) => {
        console.error("‚ùå Failed to add CSV to flow:", action.payload);
        state.error = action.payload;
      })
      .addCase(fetchFlowProperties.fulfilled, (state, action) => {
        const { flowId, properties } = action.payload;
        state.properties[flowId] = properties; // ‚úÖ properties Ï†ÄÏû•
      })
      .addCase(fetchFlowHistograms.fulfilled, (state, action) => {
        const { flowId, histograms } = action.payload;
        state.histograms[flowId] = histograms;
      })
      .addCase(fetchFlowHistograms.rejected, (state, action) => {
        console.error("‚ùå Failed to fetch histograms:", action.payload);
        state.error = action.payload;
      })
      .addCase(savePropertyCategories.fulfilled, (state, action) => {
        console.log(
          "‚úÖ Property categories successfully updated:",
          action.payload
        );
      })
      .addCase(savePropertyCategories.rejected, (state, action) => {
        console.error(
          "‚ùå Failed to update property categories:",
          action.payload
        );
        state.error = action.payload;
      });
  },
});

export const {
  initializeFlow,
  setCurrentStep,
  initializeCategories,
  updateCategory,
  updateOptimizationData,
  updatePriorities,
  initializePriorities,
} = flowSlice.actions;
export default flowSlice.reducer;
