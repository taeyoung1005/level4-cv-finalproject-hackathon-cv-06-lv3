{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. control 변수 처리\n",
    "2. 최적화 방향 처리\n",
    "3. 중요도 처리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.datasets as datasets\n",
    "import src.surrogate as surrogate\n",
    "import src.search as search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deap import base, creator, tools\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from deap import algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import attrgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/lightgbm/basic.py:357: UserWarning: Converting column-vector to 1d array\n",
      "  _log_warning(\"Converting column-vector to 1d array\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttrain's rmse: 0.0711261\tvalid's rmse: 0.0879105\n",
      "[200]\ttrain's rmse: 0.0606034\tvalid's rmse: 0.0844337\n",
      "[300]\ttrain's rmse: 0.0540944\tvalid's rmse: 0.0837656\n",
      "[400]\ttrain's rmse: 0.0491065\tvalid's rmse: 0.0835851\n",
      "[500]\ttrain's rmse: 0.0450523\tvalid's rmse: 0.0832498\n",
      "Early stopping, best iteration is:\n",
      "[515]\ttrain's rmse: 0.0444072\tvalid's rmse: 0.083166\n"
     ]
    }
   ],
   "source": [
    "load_data_func = getattr(datasets, f'melb_data')\n",
    "X_train, X_test, y_train, y_test = load_data_func('./data/melb_data_processed_04mean.csv')\n",
    "\n",
    "load_data_loader_func = getattr(datasets, f'lightgbm_load_data')\n",
    "train_loader, val_loader = load_data_loader_func(X_train, X_test, y_train, y_test)\n",
    "\n",
    "train_func = getattr(surrogate, f'lightgbm_train')\n",
    "model = train_func(train_loader, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predict_func = getattr(surrogate, f'lightgbm_predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_y = y_test[0]\n",
    "gt_x = X_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vars = ['Suburb','Rooms','Type','Method','SellerG','Distance','Postcode','Bedroom2','Bathroom','Car','Landsize','YearBuilt','CouncilArea','Lattitude','Longtitude','Regionname','Propertycount','Address_bert_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "control = ['Landsize','Distance','Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "optmize_dict = {'Landsize': 'minimize','Distance': 'maximize'}\n",
    "importance = {'Distance': 2, 'Landsize': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_min,x_max = np.min(X_train, axis=0), np.max(X_train, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vars = ['Suburb','Rooms','Type','Price','Method','SellerG','Distance','Postcode','Bedroom2','Bathroom','Car','Landsize','YearBuilt','CouncilArea','Lattitude','Longtitude','Regionname','Propertycount','Address_bert_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_set = set(control)  \n",
    "control_index = [i for i, v in enumerate(vars) if v in control_set] # var 중에 control\n",
    "\n",
    "# control_importance_dict = {v: importance[v] for v in control if v in importance}   \n",
    "control_index_to_pop_idx = {v: i+1 for i, v in enumerate(control_index)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_control_index_by_importance = sorted([i for i in control_index if vars[i] in importance.keys()], key=lambda x: importance[vars[x]]) # control중 importance 순서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pop_idx_by_importance = [control_index_to_pop_idx[i] for i in sorted_control_index_by_importance] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_optimize_dict_by_vars_idx = {vars[k]: optmize_dict[vars[k]] for k in [i for i in control_index if vars[i] in importance.keys()]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicographic_selection(population,k):\n",
    "\n",
    "    # population.sort(key=lambda ind: tuple(ind.fitness.values[0],)+tuple(ind.fitness.values[i] for i in importance.values()), reverse=True)\n",
    "    population.sort(\n",
    "        key=lambda ind: tuple(ind.fitness.values[i] * ind.fitness.weights[i] for i in range(len(ind.fitness.values))),\n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return population[:k] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.202095239120275e-07, 0.47762566363057474, -0.3309507382729003)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = tuple(1.0 if opt == 'maximize' else -1.0 for opt in sorted_optimize_dict_by_vars_idx.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax_pop_idx = [control_index_to_pop_idx[i]-1 for i in control_index if vars[i] in importance.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minmax_pop_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 2]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_pop_idx_by_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 5, 10]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "control_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'FitnessMax' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n",
      "/opt/conda/lib/python3.10/site-packages/deap/creator.py:185: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  warnings.warn(\"A class named '{0}' has already been created and it \"\n"
     ]
    }
   ],
   "source": [
    "# creator.create('FitnessMax', base.Fitness, weights=(1.0,1.0,1.0))\n",
    "creator.create('FitnessMax', base.Fitness, weights=(1.0,) + weights) # model pred + control optim \n",
    "\n",
    "creator.create('Individual', np.ndarray, fitness=creator.FitnessMax)\n",
    "def generate_individual():\n",
    "    return np.random.uniform(x_min[control_index], x_max[control_index])\n",
    "toolbox = base.Toolbox()\n",
    "toolbox.register('attr_float', generate_individual)\n",
    "# min_max 차원이 8개이기에 n을 1로 설정 하면 8개의 변수를 가진 ind 생성!\n",
    "toolbox.register('individual', tools.initIterate, creator.Individual, toolbox.attr_float)\n",
    "toolbox.register('population', tools.initRepeat, list, toolbox.individual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(population):\n",
    "    \n",
    "\n",
    "    population = np.array(population)\n",
    "    # print('population shape : ', population.shape)\n",
    "    input_data = np.array(gt_x).reshape(1,-1).repeat(len(population), axis=0)\n",
    "    input_data[:,control_index] = population\n",
    "    y_pred = predict_func(model=model, X_test=input_data)\n",
    "\n",
    "    fit_fun = []\n",
    "\n",
    "    fit_fun.append(-(y_pred - gt_y)**2)\n",
    "    # fit_fun = np.where(fit_fun > -0.01, 0, fit_fun)\n",
    "    \n",
    "    for i in sorted_pop_idx_by_importance:\n",
    "        fit_fun.append(population[:,i-1:i])\n",
    "    fit_fun = np.concatenate(fit_fun, axis=1)\n",
    "    \n",
    "    return fit_fun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "operator.attrgetter('fitness')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrgetter('fitness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register('evaluate', fitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ETA_CX = 5.0 # 초기에 작게(탐색), 점점 크게(exploitation)\n",
    "toolbox.register('mate', tools.cxSimulatedBinary, eta=ETA_CX)\n",
    "\n",
    "MUTPB = 0.2          # 돌연변이 적용 확률(전역)\n",
    "INDPB = 0.1          # 각 변수별 변이 확률\n",
    "sigma_list = [(ub - lb)/10.0 for (lb,ub) in zip(x_min, x_max)]  # 변수 범위에 따른 sigma 값 \n",
    "\n",
    "toolbox.register('mutate', tools.mutGaussian, mu=[0.0]*(len(x_min)), sigma=sigma_list, indpb=INDPB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "toolbox.register('select', tools.selTournament)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = toolbox.population(n=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Individual([1.62235919, 0.82505372, 0.74260776])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "cxpb = 0.5\n",
    "mutpb = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_clustering(population, k):\n",
    "    n, d = population.shape\n",
    "    kmeans = faiss.Kmeans(d, k, niter=20, verbose=False)\n",
    "    population = population.astype('float32')\n",
    "    kmeans.train(population)\n",
    "\n",
    "    cluster_labels = kmeans.index.search(population, 1)[1].flatten()  \n",
    "    centroids = kmeans.centroids\n",
    "    \n",
    "    return cluster_labels, centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def k_means_selection(population, k):\n",
    "#     flag = 0\n",
    "\n",
    "#     cluster_labels, centroids = kmeans_clustering(np.array(population),k=k)\n",
    "#     res = []\n",
    "#     for i in range(k):\n",
    "#         cluster_idx = np.where(cluster_labels == i)[0]\n",
    "#         cluster_population = [population[j] for j in cluster_idx]\n",
    "        \n",
    "#         # 홀수일 때 population 수 줄어듦 방지 \n",
    "#         if len(cluster_population)%2 == 0:\n",
    "#             res.extend(lexicographic_selection(cluster_population, k=len(cluster_population)//2,sorted_control_importance_rank = sorted_control_importance_rank))\n",
    "#         else:\n",
    "#             if flag == 0:\n",
    "#                 res.extend(lexicographic_selection(cluster_population, k=len(cluster_population)//2+1,sorted_control_importance_rank = sorted_control_importance_rank))\n",
    "#                 flag = 1\n",
    "#             else:\n",
    "#                 res.extend(lexicographic_selection(cluster_population, k=len(cluster_population)//2,sorted_control_importance_rank = sorted_control_importance_rank))\n",
    "#                 flag = 0\n",
    "#     return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_means_selection(population, k):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        population (list)\n",
    "        k (int): K-means에서 나눌 클러스터 개수.\n",
    "\n",
    "    Returns:\n",
    "        list: 선택된 ind 리스트.\n",
    "    \"\"\"\n",
    "    # print('population len : ',len(population))\n",
    "    adjustment_flag = False  # 클러스터 크기가 홀수일 때 조절하는 플래그\n",
    "    population_array = np.array(population)\n",
    "    \n",
    "    cluster_labels, _ = kmeans_clustering(population_array, k=k)\n",
    "    \n",
    "    selected = []\n",
    "    \n",
    "    for cluster_id in range(k):\n",
    "        cluster_indices = np.where(cluster_labels == cluster_id)[0]\n",
    "        cluster_population = [population[idx] for idx in cluster_indices]\n",
    "        cluster_size = len(cluster_population)\n",
    "        \n",
    "        # 홀수일 떄 개체수 줄어듦 방지 \n",
    "        selection_size = cluster_size // 2\n",
    "        if cluster_size % 2 == 1 and not adjustment_flag:\n",
    "            selection_size += 1\n",
    "            adjustment_flag = True\n",
    "        elif cluster_size % 2 == 1 and adjustment_flag:\n",
    "            adjustment_flag = False\n",
    "        \n",
    "        selected.extend(\n",
    "            lexicographic_selection(\n",
    "                cluster_population, \n",
    "                k=selection_size, \n",
    "            )\n",
    "        )\n",
    "    # print(len(selected))\n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n",
      "WARNING clustering 200 points to 20 centroids: please provide at least 780 training points\n"
     ]
    }
   ],
   "source": [
    "# %%capture\n",
    "for i in range(100):\n",
    "    offspring = algorithms.varAnd(population, toolbox, cxpb, mutpb)\n",
    "    population = offspring+population\n",
    "    invalid_ind = [ind for ind in population if not ind.fitness.valid]\n",
    "    fitness_scores = toolbox.evaluate(invalid_ind)\n",
    "    for ind, fit in zip(invalid_ind, fitness_scores):\n",
    "        # print(fit)\n",
    "        ind.fitness.values = tuple(fit,)\n",
    "        # print(ind.fitness.values)\n",
    "    population = k_means_selection(population, k=len(population)//10)\n",
    "    # print([i.fitness.values for i in population[:3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.202095239120275e-07, 0.47762566363057474, 0.3309507382729003)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind.fitness.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Individual([-8.8368163 ,  0.33095074,  0.47762566])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.202095239120275e-07, 0.47762566363057474, -0.3309507382729003)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuple(ind.fitness.values[i] * ind.fitness.weights[i] for i in range(len(ind.fitness.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
